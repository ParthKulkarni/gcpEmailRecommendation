X-Received: by 10.180.93.230 with SMTP id cx6mr818615wib.5.1362292544508;
        Sat, 02 Mar 2013 22:35:44 -0800 (PST)
X-BeenThere: golang-nuts@googlegroups.com
Received: by 10.180.109.8 with SMTP id ho8ls213598wib.17.canary; Sat, 02 Mar
 2013 22:35:37 -0800 (PST)
X-Received: by 10.204.146.27 with SMTP id f27mr627700bkv.6.1362292537875;
        Sat, 02 Mar 2013 22:35:37 -0800 (PST)
X-Received: by 10.204.146.27 with SMTP id f27mr627699bkv.6.1362292537861;
        Sat, 02 Mar 2013 22:35:37 -0800 (PST)
Return-Path: <dvy...@google.com>
Received: from mail-la0-x22d.google.com ([2a00:1450:4010:c03::22d])
        by gmr-mx.google.com with ESMTPS id u1si1197664bkv.1.2013.03.02.22.35.36
        (version=TLSv1 cipher=ECDHE-RSA-RC4-SHA bits=128/128);
        Sat, 02 Mar 2013 22:35:36 -0800 (PST)
Received-SPF: pass (google.com: domain of dvy...@google.com designates 2a00:1450:4010:c03::22d as permitted sender) client-ip=2a00:1450:4010:c03::22d;
Authentication-Results: gmr-mx.google.com;
       spf=pass (google.com: domain of dvy...@google.com designates 2a00:1450:4010:c03::22d as permitted sender) smtp.mail=dvy...@google.com;
       dkim=pass head...@google.com
Received: by mail-la0-x22d.google.com with SMTP id er20so4130462lab.32
        for <golan...@googlegroups.com>; Sat, 02 Mar 2013 22:35:36 -0800 (PST)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=google.com; s=20120113;
        h=mime-version:x-received:in-reply-to:references:date:message-id
         :subject:from:to:cc:content-type;
        bh=g73brLmlxjltGZTlwr/SPE/S+sczufFP0JIbXuUs7pQ=;
        b=OucirFvaM3mhh1Xqh+22f/BYXTau4ce94Wap1KSRCoKqybxoHFFpeoJFGtzISvEMko
         zNAu3azvOL8etr2dctFg8hhql4Y6sHTkURihdF/nhVpt0eNKEo3aJm2wjUVdtELhu5Of
         6wx/ozBS33bUEna0hSMWz+fTEeD9wVzYMHhau/r0SvUkxq2V288cM3kI78KmQlg6p6uz
         w5ThgqBUhow4KFVffV1B1Ce9nO731jc8LC3AwvHjLxLqaY+M3u4itWC7R5j9Ynk0r3x2
         XNchegZzNnRT8w+BX9icE8VzCFuumYcf/jD2lshj4SI23dK+03wZ7ptKRPA6bUIzF5uk
         /log==
MIME-Version: 1.0
X-Received: by 10.112.17.137 with SMTP id o9mr2880881lbd.42.1362292536536;
 Sat, 02 Mar 2013 22:35:36 -0800 (PST)
Received: by 10.114.11.36 with HTTP; Sat, 2 Mar 2013 22:35:36 -0800 (PST)
In-Reply-To: <CAFgOgC88g0tf+TNj9W=-v7H=sKQeA1x-rnrinPuPdi+yA1=itQ@mail.gmail.com>
References: <CAFgOgC9nkqCw9T3=owrYDfk6dNpBOkC0Z3K2r84upeCSCpaukw@mail.gmail.com>
	<CAFgOgC88g0tf+TNj9W=-v7H=sKQeA1x-rnrinPuPdi+yA1=itQ@mail.gmail.com>
Date: Sun, 3 Mar 2013 08:35:36 +0200
Message-ID: <CACT4Y+b3EESzPKXhX5Hjv_83BkUFtc4HsYh18TvrA88SDsK_dA@mail.gmail.com>
Subject: Re: [go-nuts] Re: Workload semantics of new scheduler queues
From: Dmitry Vyukov <dvy...@google.com>
To: "Devon H. O'Dell" <devon...@gmail.com>
Cc: golang-nuts <golan...@googlegroups.com>
Content-Type: text/plain; charset=ISO-8859-1
X-Gm-Message-State: ALoCoQkeIVrn21GlSRbkCYv9LM9AUJzZxWqcbQ27eX0doy3XMhIjul9Jo3uaegDTrWXnt3RdzGFpLvDcqmPBA2hrrw5FzHcxRfxjCBAFawMMuk4NDMBOkgSiHwgfaUsKDEtza0KXsKYNWaEgwCqR/k/pVF0cr+/eake/iyv9hZ7jCjXMjwpjMAlLOWwjQ8tblft75vXvyNvXyANPUj9EYsRgkMRN7p/njw==

On Sat, Mar 2, 2013 at 8:54 PM, Devon H. O'Dell <devon...@gmail.com> wrote:
> I think it's a net win. This is just the threadring benchmark, but on
> my Macbook Pro with 4 core 2.9GHz i7:
>
> Current:
> Devons-MacBook-Pro:shootout dho$ for i in 1 2 4; do time ./6.out
> -n=20000000; done > /dev/null
> real    0m3.025s user   0m3.018s sys    0m0.006s
> real    0m3.057s user   0m3.050s sys    0m0.006s
> real    0m3.036s user   0m3.031s sys    0m0.005s
>
> New:
> Devons-MacBook-Pro:shootout dho$ for i in 1 2 4; do time ./6.out
> -n=20000000; done > /dev/null
> real    0m2.633s user   0m2.627s sys    0m0.005s
> real    0m2.623s user   0m2.618s sys    0m0.005s
> real    0m2.645s user   0m2.639s sys    0m0.005s

How does it look with GOMAXPROCS=2 and 4?


> The pkg tests I ran don't show really great improvements but there are
> some, especially when there's higher contention over the P locks
> (which is usually true when GOMAXPROCS=1). I suspect I can make some
> additional improvements. Are there suggestions on which benchmarks I
> should run for this sort of thing?
>
> I'm not sure that the improvements would warrant trying to get this in
> to 1.1, depending on how close we are to that.

But this also resolved the other TODO to have fixed-size local queue,
which I think is more important (to prevent excessive growth of local
queues).
