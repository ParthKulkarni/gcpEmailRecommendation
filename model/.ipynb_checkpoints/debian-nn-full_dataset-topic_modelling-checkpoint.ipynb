{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing function definition and reading into thread list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b3cea9112b2463fabf83410689f8179",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=23), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import sys\n",
    "import glob\n",
    "import string\n",
    "from pprint import pprint\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "from gensim.models import CoherenceModel, LdaModel, LsiModel, HdpModel\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "from gensim.corpora import Dictionary\n",
    "import pyLDAvis.gensim\n",
    "from gensim import models\n",
    "\n",
    "import os, re, operator, warnings\n",
    "warnings.filterwarnings('ignore')  # Let's not pay heed to them right now\n",
    "%matplotlib inline\n",
    "import spacy\n",
    "nlp = spacy.load(\"en\")\n",
    "\n",
    "folder_path = \"/home/niki/Documents/BE_Project/gcpEmailRecommendation/Scraping/mini_deb/*\"\n",
    "sys.path.insert(0, '/home/niki/Documents/BE_Project/my_EmailRecommmendation/Preprocessing')\n",
    "\n",
    "\n",
    "import preprocessing\n",
    "import read_file\n",
    "import datetime\n",
    "\n",
    "\n",
    "def get_sender(msg):\n",
    "    msg = email.message_from_string(msg)\n",
    "    mfrom = msg['From'].split('<')[0]\n",
    "    return mfrom\n",
    "\n",
    "def extract_debian(text):\n",
    "    text = text.split('\\n\\n\\n')\n",
    "    header = text[0].split('\\n')\n",
    "    body = text[1]\n",
    "    sender = header[2].split(':')[1].split('<')[0]\n",
    "#     print('Sender',sender)\n",
    "#     print('Body \\n',body)\n",
    "    return sender,body\n",
    "\n",
    "def clean_debian(temp):\n",
    "    temp = temp.strip()\n",
    "    temp = re.sub('\\n+','\\n',temp)\n",
    "    temp = re.sub('\\n',' ',temp)\n",
    "    temp = re.sub('\\t',' ',temp)\n",
    "    temp = re.sub(' +',' ',temp)\n",
    "    return temp\n",
    "\n",
    "def deb_lemmatize(doc):        \n",
    "    doc = nlp(doc)\n",
    "    article, skl_texts = [],[]\n",
    "    for w in doc:\n",
    "        if w.text != '\\n' and not w.is_stop and not w.is_punct and not w.like_num:\n",
    "            article.append(w.lemma_)\n",
    "        if w.text == '\\n':                \n",
    "            skl_texts.append(article)\n",
    "            article = []       \n",
    "    return skl_texts\n",
    "\n",
    "def deb_toppostremoval(temp):\n",
    "    strings = temp.splitlines()\n",
    "    temp = ''\n",
    "    for st in strings:\n",
    "        st = st.strip()\n",
    "        if len(st)>0:\n",
    "            if st[0]=='>':\n",
    "                continue\n",
    "            else:\n",
    "                temp += '\\n' + st\n",
    "    return temp\n",
    "\n",
    "df = pd.DataFrame(columns=['body','replier', 'thread_no'])\n",
    "users = []\n",
    "folder = glob.glob(folder_path)\n",
    "th_no = 0\n",
    "obj = preprocessing.preprocess()\n",
    "cnt = 0\n",
    "count_file = 0\n",
    "thread_list=[]\n",
    "try:\n",
    "    for fol in tqdm_notebook(folder):\n",
    "        files = glob.glob(fol+'/*.txt')\n",
    "        flag = 0\n",
    "        t = ''\n",
    "        threads = []\n",
    "        for file in files:\n",
    "            ob = read_file.file_content(file)\n",
    "            ob.read_file_content()\n",
    "            threads.append(ob.mail)\n",
    "            count_file += 1\n",
    "        sorted_threads = sorted(threads, key=lambda ke: datetime.datetime.strptime(ke['Date'],'%a, %d %b %Y %H:%M:%S %z'))\n",
    "        thread_list.append(sorted_threads)\n",
    "except:\n",
    "    print(fol)\n",
    "print(len(thread_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "92\n"
     ]
    }
   ],
   "source": [
    "text = []\n",
    "t = ''\n",
    "for thr in thread_list:\n",
    "    for mail in thr:\n",
    "        temp = ''\n",
    "        sender = mail['From']\n",
    "        temp   = mail['content']\n",
    "        users.append(sender)\n",
    "        temp = deb_toppostremoval(temp)\n",
    "        temp = obj.replace_tokens(temp)\n",
    "        temp = clean_debian(temp)\n",
    "        if temp == '':\n",
    "            cnt += 1\n",
    "            continue\n",
    "        t += temp + '\\n'\n",
    "print(cnt)\n",
    "print(count_file)\n",
    "t = t[:-2]\n",
    "text = deb_lemmatize(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = gensim.models.Phrases(text)\n",
    "text = [bigram[line] for line in text]\n",
    "\n",
    "dictionary = Dictionary(text)\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)\n",
    "\n",
    "corpus = [dictionary.doc2bow(txt) for txt in text]\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "corpus = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.149*\"package\" + 0.120*\"on\" + 0.105*\"bug\" + 0.102*\"not\" + 0.070*\"-PRON-\" + 0.070*\"signature.asc\" + 0.058*\"want\" + 0.055*\"url\" + 0.055*\"+_number\" + 0.040*\"work\"'),\n",
       " (1,\n",
       "  '0.142*\"-PRON-\" + 0.127*\"url\" + 0.093*\">\" + 0.090*\"on\" + 0.090*\"<\" + 0.075*\"+_number\" + 0.072*\"work\" + 0.068*\"be\" + 0.050*\"package\" + 0.040*\"want\"'),\n",
       " (2,\n",
       "  '0.214*\"debian\" + 0.190*\"+_number\" + 0.176*\"url\" + 0.083*\"file\" + 0.058*\">\" + 0.056*\"<\" + 0.052*\"package\" + 0.049*\"-PRON-\" + 0.025*\"be\" + 0.025*\"on\"'),\n",
       " (3,\n",
       "  '0.125*\"good\" + 0.092*\"need\" + 0.083*\"not\" + 0.083*\"debian\" + 0.076*\"url\" + 0.061*\"-PRON-\" + 0.061*\"signature.asc\" + 0.060*\"be\" + 0.058*\"file\" + 0.056*\"package\"'),\n",
       " (4,\n",
       "  '0.163*\"-PRON-\" + 0.139*\">\" + 0.114*\"be\" + 0.083*\"package\" + 0.081*\"not\" + 0.069*\"want\" + 0.060*\"+_number\" + 0.060*\"<\" + 0.023*\"url\" + 0.023*\"need\"'),\n",
       " (5,\n",
       "  '0.161*\"package\" + 0.104*\">\" + 0.101*\"<\" + 0.093*\"url\" + 0.085*\"need\" + 0.061*\"be\" + 0.060*\"debian\" + 0.058*\"not\" + 0.054*\"+_number\" + 0.053*\"signature.asc\"'),\n",
       " (6,\n",
       "  '0.168*\"debian\" + 0.113*\">\" + 0.112*\"signature.asc\" + 0.110*\"<\" + 0.105*\"the\" + 0.092*\"+_number\" + 0.058*\"file\" + 0.058*\"good\" + 0.045*\"-PRON-\" + 0.015*\"package\"'),\n",
       " (7,\n",
       "  '0.114*\"bug\" + 0.112*\"good\" + 0.094*\"debian\" + 0.083*\"want\" + 0.075*\"-PRON-\" + 0.073*\"not\" + 0.069*\"be\" + 0.053*\"file\" + 0.049*\"the\" + 0.046*\">\"'),\n",
       " (8,\n",
       "  '0.122*\"package\" + 0.114*\"need\" + 0.094*\"the\" + 0.066*\"want\" + 0.065*\"on\" + 0.057*\"good\" + 0.052*\"bug\" + 0.051*\"debian\" + 0.048*\"+_number\" + 0.048*\"<\"'),\n",
       " (9,\n",
       "  '0.152*\"work\" + 0.110*\"file\" + 0.089*\"need\" + 0.076*\"not\" + 0.069*\"<\" + 0.061*\"the\" + 0.055*\"url\" + 0.054*\"bug\" + 0.048*\"signature.asc\" + 0.047*\"debian\"')]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel = LdaModel(corpus=corpus, num_topics=10, id2word=dictionary)\n",
    "ldamodel.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
