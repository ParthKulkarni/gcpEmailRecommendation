To : jonas@jones.dk
Subject : Re: Re: Re: Concerns to software freedom when packaging deep-learning based appications.
From : Lumin <cdluminate@gmail.com>
Date : Fri, 13 Jul 2018 16:13:26 +0000
Message-id : 20180713161326.GA11101@Asuna
In-reply-to : <[ðŸ”Ž]Â 153149656490.1905.1384960534957541286@auryn.jones.dk>


Hi Jonas,
> Seems you elaborated only that it is ridiculously slow so use CPUs
> instead of [non-free blob'ed] GPUs - not that it is *impossible to use
> CPUs.
> 
> If I am mistaken and you addressed the _possibility_ (not popularity) of
> reproducing/modifying/researching with CPUs, then I apologize for
> missing it, and as if you can please highlight the the essential part of
> your point.
Sorry if I didn't make my point clear.
>From a technical point of view, CPU can do the same work as GPU.
So it is definitely possible, even if it takes 100 years with CPU.
>From human's point of view, a pure free software stack can do the
same thing. But one have to wait for, say, 1 year. In this
case, in order to make sense, one is forced to use non-free.
Based on this observation, I raised the topic in the original post,
because the freedom to modify/reproduce a work is limited by,
as concluded previously, license of big data, and the noticable
time/device cost. Hence I asked people how we should deal with
related works if some of us want to integrate such work into Debian.
> Bill Gates is famously quoted for ridiculing the need for more than 640
> kilobytes of memory in personal computers.  Computer designs changed
> since then.